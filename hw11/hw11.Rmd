---
title: "BACS HW11"
author: "109062710"
date: "5/5/2021"
output: html_document
---

```{r, include=FALSE}
library(dplyr)
library(ISLR)
```

## Question 1

#### a. Let’s dig into what regression is doing to compute model fit

##### i. Plot Scenario 2, storing the returned points
```{r}
pts <- data.frame(
  x = c(
    -4.704724, 3.966620, 3.448928, 11.861426, 11.473157,
    20.662193, 18.462001, 27.909883, 25.709691, 35.416420,
    32.957382, 41.887572, 41.369880, 49.652955, 7.331619
  ),
  y = c(
    4.682789, -1.593332, 14.096971, 7.472177, 22.465133,
    16.537685, 31.879314, 25.951867, 41.293496, 29.089927,
    45.826250, 39.550129, 50.010331, 48.615637, 5.728810
  )
)
```

##### ii. Run a linear model of x and y points to confirm the R2 value reported by the simulation

```{r}
regr <- lm(y ~ x, data = pts)
summary(regr)
```

#### iii. Add line segments to the plot 

1. Get values of $\hat{y}$ (estimated values)

```{r}
y_hat <- regr$fitted.values
y_hat
```

2. Add segments

```{r}
plot(pts)
abline(lm(pts$y ~ pts$x))
segments(pts$x, pts$y, pts$x, y_hat, col="red", lty="dotted")
```

##### iv. Use only `pts$x, pts$y, y_hat and mean(pts$y)` to compute SSE, SSR and SST, and verify $R^2$

```{r}
sse <- sum((fitted(regr) - mean(pts$y))^2)
ssr <- sum((fitted(regr) - pts$y)^2)
sst <- sse + ssr
r2 <- 1 - (ssr / sst)
```

#### b. Comparing scenarios 1 and 2, which do we expect to have a stronger $R^2$?

<p style="color: blue;">
For the first scenario, $R^2$ will be very close to $+1$ since most of the data points are sitting at or close to the increasing regression line. However, the second scenario's $R^2$ value won't be as high as the first scenario's, but it still will be near $1$.
</p>

<p style="color: red;">
In this case, the first scenario will have a stronger $R^2$.
</p>

#### c. Comparing scenarios 3 and 4, which do we expect to have a stronger $R^2$?

<p style="color: blue;">
In the third scenario, the $R^2$ will be close to $-1$ since most of the data points are sitting on or close to the decreasing regression line. However, the fourth scenario's $R^2$ value won't be as high as the third scenario's, but it still will be near $-1$.
</p>

<p style="color: red;">
In this case, the third scenario will have a stronger $R^2$.
</P

#### d. Comparing scenarios 1 and 2, which do we expect has bigger/smaller SSE, SSR, and SST?

#### e. Comparing scenarios 3 and 4, which do we expect has bigger/smaller SSE, SSR, and SST?

## Question 2

```{r}
auto <- Auto
head(auto)
```

```{r}
summary(auto)
```

#### a. Let’s first try exploring this data and problem

##### i. Visualize the data in any way you feel relevant

##### ii. Report a correlation table of all variables, rounding to two decimal places

##### iii. From the visualizations and correlations, which variables seem to relate to mpg?

##### iv. Which relationships might not be linear? 

##### v. Are there any pairs of independent variables that are highly correlated r > 0.7?

#### b. Let’s create a linear regression model where mpg is dependent upon all other suitable variables 

##### i. Which independent variables have a ‘significant’ relationship with mpg at 1% significance?

##### ii. Looking at the coefficients, is it possible to determine which independent variables are the most effective at increasing mpg? If so, which ones, and if not, why not? (hint: units!)

#### c. Let’s try to resolve some of the issues with our regression model above.

##### i. Create fully standardized regression results: are these slopes easier to compare? (note: consider if you should standardize origin)

##### ii. Regress mpg over each non significant independent variable, individually. Which ones become significant when we regress mpg over them individually?

##### iii. Plot the density of the residuals: are they normally distributed and centered around zero? (get the residuals of a fitted linear model, e.g. `regr <- lm(...)`, using `regr$residuals`

## Reference:
[R SQUARED: SST, SSE AND SSR](https://rinterested.github.io/statistics/rsquare.html)
[The Correlation Coefficient (r)](https://sphweb.bumc.bu.edu/otlt/MPH-Modules/PH717-QuantCore/PH717-Module9-Correlation-Regression/PH717-Module9-Correlation-Regression4.html)